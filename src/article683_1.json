[
    {
        "url": "https://www.politico.com/magazine/story/2016/09/police-robots-ethics-debate-214273?cmpid=sf",
        "title": "Is Police Use of Force About to Get Worse—With Robots?",
        "authors": [
            {
                "name": "Paul Scharre",
                "link": null
            },
            {
                "name": "Michael C. Horowitz",
                "link": null
            },
            {
                "name": "Glenn Thrush",
                "link": null
            },
            {
                "name": "E.B. Boyd",
                "link": null
            }
        ],
        "publisher": "www.politico.com",
        "publish_date": "2016-09-22",
        "text": "Email\nSign Up\nBy signing up you agree to receive email newsletters or alerts from POLITICO. You can unsubscribe at any time.\nAP Images\nIs Police Use of Force About to Get Worse—With Robots?\nThe increasing deployment of robots to disarm or subdue suspects is stirring ethical debate.\nBy E.B. BOYD\nSeptember 22, 2016\nPolice robots are all over the news. Early Monday morning, FBI agents and New Jersey police officers used a bomb-squad robot to try to defuse the makeshift bombs found near a train station in Elizabeth. (The explosives ended up detonating after police used the machine to try to cut a wire.) Earlier this month, sheriff’s deputies from Los Angeles used a robot to disarm a violent suspect who had barricaded himself inside a berm in a Southern California desert. And last Friday, another robot was used to force doors open as police searched for a gunman hiding out in an Amtrak train.\nBut perhaps the most ground-breaking—and potentially unnerving—case of robot-enabled policing took place in July when officers in Dallas used a robot to subdue a gunman, and ended up killing him. The man, later identified as Micah X. Johnson, had shot and killed police officers at a protest in the city’s downtown. His rampage left five officers dead and at least nine other people injured. The suspect fled into a local community college (not a parking structure, as had initially been reported) where he barricaded himself in an alcove at the end of a corridor. The police on his tail couldn’t approach because Johnson was still firing at them periodically, and there was nowhere to take cover in the corridor. During the standoff, Johnson told the officers he wanted to kill more people, and he said he had planted bombs in the area. With about 58 students and college staff still locked down inside the building—including eight people sheltering in a room on the floor below the shooter—the officers decided they could not wait Johnson out. Instead, they placed plastic explosives on a robot and sent it down the corridor. When it got to the alcove, they detonated the explosives, ultimately killing Johnson.\nStory Continued Below\nThe news that the Dallas police department had killed a suspect using a robot shocked the country. It struck many as ruthless and excessive, if not downright illegal. To many, the killing seemed like an extra-judicial execution. It has provoked new fears at a time when police across the United States are being accused of excessive use of force, especially against blacks, including recent incidents just this past week in Tulsa, Okla, and Charlotte, N.C.\nFor some critics, the idea of using bomb-enabled police robots to kill suspects could make matters only worse, calling to mind images of Terminators run amok or military drones taking out wedding parties. It has also reignited debates about “militarized policing.”\nBy GLENN THRUSH\n“When things get easy, they tend to get overused,” said Jay Stanley, an American Civil Liberties Union policy analyst who studies the civil-liberties implications of new technologies. He is concerned that the Dallas incident—which experts say is the first known case of police using a robot to deploy lethal force—could be the beginning of a slippery slope. “The kind of incident where there is a clear and present danger represents the tip of a very large pyramid,” he said.\nThere is evidence the Dallas police resorted to plastic explosives only because there were no other viable options. Thor Eells, chairman of the National Tactical Officers Association, told POLITICO that the Dallas police were hoping to take Johnson alive, going so far as bringing a trauma surgeon to the scene to begin treating Johnson if he survived the blast. The plastic explosives were necessary, experts say, because the officers needed to make sure Johnson would be incapacitated immediately (and thus unable to trigger his bombs). Both tear gas and pepper spray, as painful as they are, would have left him functional, and a “flash-bang” grenade ran the risk of detonating any bombs Johnson might have on him.\nStill, Dallas’ robot-enabled killing raises a host of questions that the wider society is still grappling with. “Does this remain something that is only used in extraordinary circumstances?” asked Stanley. “Or do police departments start clamoring for robots specifically designed to use force?”\nStanley believes armed robots could make police officers quicker to pull a trigger, an unnerving prospect at a time when civil liberties activists say too many police are still too quick to do that already. “Let’s say there’s a protest, and there aren’t any police on the scene,” he said, “and a robot starts spraying pepper spray, or tear gas, or rubber bullets, on the crowd, and they do it with poor situational awareness”—the cameras on robots don’t provide the same visual acuity to their operators that a human on scene would have organically—“and they hit people who are not involved, or they do it when it’s not necessary.”\nSWAT experts push back against such fears. They point to existing laws that currently govern the situations in which law enforcement agencies may use force. “I am still legally responsible for having to explain and justify [any] level of force,” said Eells. “The mechanism of how the force is delivered is irrelevant to the courts.” And unlike firearms, which are distributed to all officers, only specialized SWAT teams own the large, expensive robots capable of killing a person. “You’re not going to see a plethora of these things in the future,” said Sid Heal, president of the California Association of Tactical Officers who, while serving in the Los Angeles Sheriff’s Department, was a national leader in assessing and pioneering new technologies.\nStanley counters, however, that every new technology introduces gray areas in which new kinds of abuse can seep in. He points to Tasers. Laws concerning use of force govern Tasers the same way they govern robots or pistols. “As it happens, [Tasers] are vastly overused,” Stanley said. “They’re often used to get recalcitrant suspects to cooperate with the police [or] as a punishment for dissing a cop.” Plus, though they were promoted as “less-than-lethal” alternatives to guns, they have nevertheless killed people. “Often, the way new technologies play out on the ground is not the way you would expect,” Stanley said.\nAll of this raises questions about whether new laws are needed to govern robots and drones. Some states, including Oregon, Virginia and Wisconsin, have outright banned law enforcement agencies from arming drones. Only North Dakota, so far, has explicitly permitted police to put weapons on drones, though only with less-than-lethal munitions, such as tear gas, bean bags and Tasers. In states with no such laws, police departments simply operate as they see fit, within the context of existing law.\n***\nRobots are not new to policing. Most people are familiar with the bomb-squad versions, which have been in use for about 20 years. The large machines are maneuvered by remote control to inspect suspicious objects, and sometimes detonate them, while keeping humans out of harm’s way.\nWhat’s less well known is that SWAT teams are also increasingly using robots. The most common application is reconnaissance. In the middle of a standoff, where a suspect is barricaded in a room or a building, SWAT officers can toss small, camera-bearing devices, nicknamed “throwbots,” into a building to assess the situation. Robots can be used to deliver phones to people police are negotiating with. They can be used to search a parking lot for a suspect hiding under a car—instead of having an officer lower their head and risk getting it blown off.\nBy MICHAEL C. HOROWITZ and PAUL SCHARRE\nRobots have been used in more creative situations as well. In one case, a SWAT team used a robot to reach through a window and pull a blanket off of a suicidal person to check whether he had a weapon. (He didn’t.) In other cases, robots have swept homes for booby traps, and they’re often used to toss tear gas or pepper spray into rooms, to disable suspects before officers enter. In the California desert earlier this month, sheriff’s deputies used a robot to creep up behind the suspect and take away his rifle while he was distracted by helicopters and police officers yelling at him through loudspeakers.\nPolice argue that these kinds of robots actually help save lives. Officers who are executing a search warrant in a volatile situation can send a robot in first. Send in an armed human, and the situation could quickly escalate into a shooting match. Send in a robot, and police can get a lay of the land and even start communicating with a suspect before putting an officer into the mix. Using a robot to approach the suspect in the desert earlier this month kept everyone safe, said Capt. Jack Ewell, head of the Los Angeles County Sheriff Department’s Special Enforcement Division. As soon as the suspect realized his weapon was gone, he surrendered. “It prevented a potential shooting in which he could have been harmed, we could have been harmed, or a stray bullet could have been gone somewhere,” Ewell said.\nBut using a robot to kill? That’s something new. The SWAT experts POLITICO spoke with said they didn’t know of a previous situation where a police department had used a robot to deploy lethal force. But they added it’s not likely we’ll suddenly see police departments regularly using robots this way. For one thing, robots like the one in Dallas are expensive. Most SWAT teams can’t afford them. The machines are large and unwieldy, weighing 400 to 800 pounds. Police departments need trailers just to move them about. They aren’t particularly mobile. While they can roll down a simple corridor or street, they can’t maneuver through a building as quickly a human can. (The robot used in Dallas, a Remotec Andros Mark V-A1, weighs nearly 800 pounds, and it can go only 3.5 mph.) And while robots can be outfitted with a firearm, the robot is never going to have the same agility in handling a dynamic situation as a well-trained SWAT officer.\nWe also won’t soon be seeing autonomous machines—Terminator-style “killer robots” that act on their own. Even the military doesn’t give its robots independent shooting power. Military drones do perform certain actions on their own—like flying to a specific location or circling a target. But when it comes to pulling a trigger, the military still insists on keeping a “man in the loop.” Police departments are no different. “We recognize the grave responsibility we have with making the decision to use force,” said NTOA’s Eells, who is also commander of the Colorado Springs SWAT team. “There’s a tremendous reluctance to give that up.”\n***\nAs much as anything, the public’s reaction to the Dallas robot underlines the gulf between police departments and the public in their understandings of the new devices. In a news conference immediately following the standoff, police Chief David Brown said the department had used a “bomb robot.” The shorthand was clear to him; he meant the department had used a robot belonging to the bomb squad. But many in the public understood those words differently: that there was a robot designed to be a bomb. This, as much as anything, might be what many found so upsetting.\nAnd while it was clear to law enforcement officers across the country that the Dallas SWAT team’s primary goal was to subdue Johnson—not kill him—the lack of detail released by Dallas police about the challenges it faced in apprehending Johnson, especially in an age when so many people are already up in arms about police killings of black men, left many in the public with the impression that the police simply sought to execute him. Even those who study this subject were left confused about the police’s objectives. “I was surprised that they did purposely kill someone with a robot,” said one expert.\nPolice departments naturally view new technologies just as additional tools that don’t fundamentally change the parameters in which they operate. The public, however, often sees new devices as potentially threatening. Take Seattle, for example. Several years ago, the city’s police department bought two Draganflyer X6 drones—essentially hand-held mini-copters—as reconnaissance tools for use during hostage standoffs and search-and-rescue operations. Seattle residents, however, immediately became alarmed about the ways the devices could threaten personal privacy, and they rose up against them. The backlash might have surprised the Seattle police, knowing as they did that any surveillance inside a private space would require the same kind of warrant as an inspection done in person. In the face of the outcry, however, the city’s mayor shut the program down. (The copters were gifted to the LA police.) The implications, according to UW’s Calo, are potentially unfortunate. “Now, if a kid gets lost in a park,” he said, “the Seattle police department can’t roll out their drone to find them.”\nBy Colin Woodard\nIn a 2012, Lt. Anthony Martinez of the Fresno police department wrote a thesis for California’s Law Enforcement Command College that pinpointed this very problem. The paper examined how new types of robots could potentially save police lives by removing humans from scenarios in which robots could perform equally well. Martinez surveyed representatives from law enforcement and civic groups about what they saw as the potential challenges. Costs and legal questions certainly came up, but the top concern was society’s acceptance. Take the example of a robot performing an initial house search. “From a law enforcement perspective, it seems like a no-brainer,” Martinez said, because you’re reducing the chance an officer will get hurt. “But if you flip that around, people might not be ready to have a robot come into their house and tell them what to do.” In order to get the public to accept the use of robots, Martinez wrote in his paper, police departments first need to get the public familiar with them.\nThat makes the Dallas operation a potential game-changer. Now that the public has seen a robot deploy force, previous institutional reluctance to use the devices this way might start to break down. “Public perception is an important part of this,” Heal said. Commanders who before might have been reluctant to authorize the use of force by a robot, he said, “now see that their careers are survivable.”\nThe fact that we might see novel uses of robots in critical situations is why the ACLU’s Jay Stanley thinks there needs to be more discussion of what communities are willing to accept, especially in today’s incendiary environment. “This has started a whole new conversation,” he said. “It’s worth pausing to think about what it means for us as a society.”\nThe Friday Cover\n",
        "quotes": [
            [
                "When things get easy, they tend to get overused,",
                "Jay Stanley",
                true
            ],
            [
                "The kind of incident where there is a clear and present danger represents the tip of a very large pyramid,",
                "Stanley",
                true
            ],
            [
                "Does this remain something that is only used in extraordinary circumstances?",
                "Stanley",
                true
            ],
            [
                "Or do police departments start clamoring for robots specifically designed to use force?",
                "Stanley",
                true
            ],
            [
                "Let’s say there’s a protest, and there aren’t any police on the scene,",
                "Stanley",
                true
            ],
            [
                "and a robot starts spraying pepper spray, or tear gas, or rubber bullets, on the crowd, and they do it with poor situational awareness",
                "Stanley",
                false
            ],
            [
                "and they hit people who are not involved, or they do it when it’s not necessary.",
                "Stanley",
                false
            ],
            [
                "I am still legally responsible for having to explain and justify [any] level of force,",
                "Eells",
                true
            ],
            [
                "The mechanism of how the force is delivered is irrelevant to the courts.",
                "Eells",
                true
            ],
            [
                "You’re not going to see a plethora of these things in the future,",
                "Sid Heal",
                true
            ],
            [
                "As it happens, [Tasers] are vastly overused,",
                "Stanley",
                true
            ],
            [
                "They’re often used to get recalcitrant suspects to cooperate with the police [or] as a punishment for dissing a cop.",
                "Stanley",
                true
            ],
            [
                "Often, the way new technologies play out on the ground is not the way you would expect,",
                "Stanley",
                true
            ],
            [
                "It prevented a potential shooting in which he could have been harmed, we could have been harmed, or a stray bullet could have been gone somewhere,",
                "Ewell",
                true
            ],
            [
                "We recognize the grave responsibility we have with making the decision to use force,",
                "Ewell",
                true
            ],
            [
                "There’s a tremendous reluctance to give that up.",
                "Eells",
                true
            ],
            [
                "I was surprised that they did purposely kill someone with a robot,",
                "",
                true
            ],
            [
                "Now, if a kid gets lost in a park,",
                "",
                true
            ],
            [
                "the Seattle police department can’t roll out their drone to find them.",
                "",
                false
            ],
            [
                "From a law enforcement perspective, it seems like a no-brainer,",
                "Martinez",
                true
            ],
            [
                "But if you flip that around, people might not be ready to have a robot come into their house and tell them what to do.",
                "Martinez",
                true
            ],
            [
                "Public perception is an important part of this,",
                "",
                true
            ],
            [
                "now see that their careers are survivable.",
                "",
                false
            ],
            [
                "This has started a whole new conversation,",
                "",
                true
            ],
            [
                "It’s worth pausing to think about what it means for us as a society.",
                "",
                true
            ]
        ],
        "links": {
            "articles": [
                "https://www.politico.com/magazine/story/2014/11/killer-robots-save-lives-113010",
                "https://www.politico.com/magazine/story/2014/02/pittsburgh-robots-technology-103062"
            ],
            "gov_pgs": [],
            "unsure": []
        },
        "key_words": [
            "robot",
            "suspect",
            "officers",
            "swat",
            "law",
            "robots",
            "dallas",
            "worsewith",
            "force",
            "johnson",
            "used"
        ]
    }
]